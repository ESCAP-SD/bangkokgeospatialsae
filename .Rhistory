# saveRDS(results, "results.rds")
results <- readRDS("results.rds")
results <- unlist(results)
results <- as_tibble(results)
colnames(results) <- "results"
results$sim <- 1:nrow(results)
results$temp <- 1
ggplot(results) +
geom_histogram(aes(x = results, y = after_stat(count / sum(count))), color = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(temp)
results
nrow(results)
ggplot(results) +
geom_histogram(aes(x = results, y = after_stat(count / sum(count))), color = "transparent", fill = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(temp)
ggplot(results %>% filter(hist<=1000)) +
geom_histogram(aes(x = results, y = after_stat(count / sum(count))), color = "transparent", fill = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(temp)
ggplot(results %>% filter(sim<=1000)) +
geom_histogram(aes(x = results, y = after_stat(count / sum(count))), color = "transparent", fill = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(temp)
annualmean <- weighted.mean(icrisat$in_poverty_wave, icrisat$weight)
monthlymean <- weighted.mean(icrisat$in_poverty, icrisat$weight)
temp <- icrisat
# wrapper <- function(i){
#   set.seed(23405 + i)
#   temp$random <- runif(nrow(temp))
#   return <- c(temp %>%
#     group_by(hhid, year) %>%
#     arrange(hhid, year, random) %>%
#     filter(row_number()==1) %>%
#     ungroup() %>%
#     summarize(in_poverty = weighted.mean(in_poverty, weight)) %>%
#     pull(in_poverty))
# }
# results <- mclapply(1:10000, wrapper)
# # saving so I don't have to run this every time I want to knit
# saveRDS(results, "results.rds")
results <- readRDS("results.rds")
results <- unlist(results)
results <- as_tibble(results)
colnames(results) <- "results"
results$sim <- 1:nrow(results)
results$temp <- 1
results
annualmean <- weighted.mean(icrisat$in_poverty_wave, icrisat$weight)
monthlymean <- weighted.mean(icrisat$in_poverty, icrisat$weight)
temp <- icrisat
# wrapper <- function(i){
#   set.seed(23405 + i)
#   temp$random <- runif(nrow(temp))
#   return <- c(temp %>%
#     group_by(hhid, year) %>%
#     arrange(hhid, year, random) %>%
#     filter(row_number()==1) %>%
#     ungroup() %>%
#     summarize(in_poverty = weighted.mean(in_poverty, weight)) %>%
#     pull(in_poverty))
# }
# results <- mclapply(1:10000, wrapper)
# # saving so I don't have to run this every time I want to knit
# saveRDS(results, "results.rds")
results <- readRDS("results.rds")
results <- unlist(results)
results <- as_tibble(results)
colnames(results) <- "results"
results$sim <- 1:nrow(results)
temp <- c()
for (i in 1:1000){
temp <- rbind(temp, cbind(results[1:i,], hist = i))
}
temp
temp <- as_tibble(temp)
summary(temp |> filter(hist<=1000))
ggplot(temp %>% filter(hist<=1000)) +
geom_histogram(aes(x = results), color = "#006334", binwidth = 0.0005) +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(hist, state_length = 1, transition_length = 2)
annualmean <- weighted.mean(icrisat$in_poverty_wave, icrisat$weight)
monthlymean <- weighted.mean(icrisat$in_poverty, icrisat$weight)
temp <- icrisat
# wrapper <- function(i){
#   set.seed(23405 + i)
#   temp$random <- runif(nrow(temp))
#   return <- c(temp %>%
#     group_by(hhid, year) %>%
#     arrange(hhid, year, random) %>%
#     filter(row_number()==1) %>%
#     ungroup() %>%
#     summarize(in_poverty = weighted.mean(in_poverty, weight)) %>%
#     pull(in_poverty))
# }
# results <- mclapply(1:10000, wrapper)
# # saving so I don't have to run this every time I want to knit
# saveRDS(results, "results.rds")
results <- readRDS("results.rds")
results <- unlist(results)
results <- as_tibble(results)
colnames(results) <- "results"
results$sim <- 1:nrow(results)
temp <- c()
for (i in 1:1000){
temp <- rbind(temp, cbind(results[1:i,], hist = i))
}
temp <- as_tibble(temp)
ggplot(temp %>% filter(hist %in% c(999, 1000))) +
geom_histogram(aes(x = results, y = after_stat(count / sum(count))), color = "transparent", fill = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(hist, state_length = 1, transition_length = 2)
ggplot(temp %>% filter(hist %in% c(999, 1000))) +
geom_histogram(aes(x = results)), color = "transparent", fill = "transparent") +
ggplot(temp %>% filter(hist %in% c(999, 1000))) +
geom_histogram(aes(x = results)), color = "transparent", fill = "transparent") +
ggplot(temp %>% filter(hist %in% c(999, 1000))) +
geom_histogram(aes(x = results), color = "transparent", fill = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(hist, state_length = 1, transition_length = 2)
ggplot(temp %>% filter(hist %in% c(999, 1000))) +
geom_histogram(aes(x = results), color = "transparent") +
geom_vline(xintercept = monthlymean, color = "#777d78", linetype = "dashed") +
geom_vline(xintercept = annualmean, color = "#340063", linetype = "dashed") +
labs(x = "Mean", y = "Count") +
scale_x_continuous(breaks = seq(from = 0.28, to = 0.42, by = 0.02), limits = c(0.28, 0.42)) +
scale_y_continuous(breaks = seq(from = 0, to = 50, by = 10), limits = c(0, 50)) +
annotate("text", label = "Annual mean\n(low-frequency mean)", x = annualmean, y = 10, color = "#340063") +
annotate("text", label = "Monthly mean\n(high-frequency mean)", x = monthlymean, y = 10, color = "#777d78") +
transition_states(hist, state_length = 1, transition_length = 2)
temp
library(haven)
temp <- read_sav("/Users/Josh/Dropbox/Papers/malawiimagery/data/mics/Malawi MICS6 SPSS Datasets/hl.sav")
View(temp)
knitr::opts_chunk$set(echo = FALSE, dev = "png") # NOTE: switched to png instead of pdf to decrease size of the resulting pdf
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
#ifelse(options$size != "a", paste0("\n \\", "tiny","\n\n", x, "\n\n \\normalsize"), x)
ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
library(tidyverse)
library(kableExtra)
library(fixest)
library(ggpubr)
library(RColorBrewer)
library(haven)
library(mfx)
library(nnet)
library(survival)
library(survminer)
df <- read_dta("week3files/data.dta")
data(iris)
multinomresults <- multinom(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
library(survminer)
KM <- survfit(Surv(time = time, event = status) ~ 1, data = diabetic)
ggsurvplot(KM) +
labs(y = "Survival probability", x = "Time (months)") +
theme(plot.background = element_rect(fill = "#f0f1eb", color = "#f0f1eb"))
ggsurvplot(KM) +
labs(y = "Survival probability", x = "Time (months)")
ggsurvplot(KM)$plot +
labs(y = "Survival probability", x = "Time (months)") +
scale_color_discrete("Treatment:", labels = c("No", "Yes")) +
theme(legend.position = c(0.1, 0.2)) +
theme(plot.background = element_rect(fill = "#f0f1eb", color = "#f0f1eb"))
KM <- survfit(Surv(time = time, event = status) ~ 1, data = diabetic)
ggsurvplot(KM)$plot +
labs(y = "Survival probability", x = "Time (months)") +
theme(plot.background = element_rect(fill = "#f0f1eb", color = "#f0f1eb"))
library(tidyverse)
temp <- read_csv("/Users/Josh/Downloads/Geospatial Data in R_participants.csv")
temp
temp$groups <- sample(1:4, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:4, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:5, nrow(temp), replace = TRUE)
table(temp$groups)
temp$groups <- sample(1:nrow(temp), nrow(temp), replace = FALSE)
temp <- temp |> arrange(groups)
temp
temp$groups <- ceiling(temp$groups/4)
temp
temp$groups <- sample(1:nrow(temp), nrow(temp), replace = FALSE)
temp <- temp |> arrange(groups)
temp$groups <- ceiling(temp$groups/5)
temp
temp$groups <- sample(1:nrow(temp), nrow(temp), replace = FALSE)
temp <- temp |> arrange(groups)
temp$groups <- ceiling(temp$groups/3)
temp
temp$group[temp$`ID number`==202331010] <- 4
temp$groups[temp$`ID number`==202331010] <- 4
temp$groups[temp$`ID number`==202432081] <- 3
table(temp$groups)
write_csv("/Users/Josh/Downloads/groups.csv")
write_csv(temp, "/Users/Josh/Downloads/groups.csv")
temp
temp <- temp |> select(-group)
temp
write_csv(temp, "/Users/Josh/Downloads/groups.csv")
getwd()
getwd()
getwd()
library(nycflights13)
glimpse(flights)
library(tidyverse)
glimpse(flights)
table <- flights |> group_by(origin) |> summarize(meandep = mean(dep_delay, na.rm = TRUE))
table
install.packages("kableExtra")
install.packages("kableExtra")
library(terra)
?aggregate
library(sf)
?aggregate
?aggregate
library(terra)
library(sf)
?aggregate
?terra::aggregate
#| label: setup
#| include: false
knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)
library(tidyverse)
library(sf)
library(terra)
library(tidyterra)
library(cowplot)
library(kableExtra)
library(haven)
Sys.setenv("RETICULATE_PYTHON" = "~/Library/r-miniconda-arm64/envs/RGEEDIM/bin/python3.9")
library(rgeedim)
# short duration token
gd_authenticate(auth_mode = "gcloud")
# initialize and should be good to go
gd_initialize()
kdisgreen <- "#006334"
accent <- "#340063"
accent2 <- "#633400"
kdisgray <- "#A7A9AC"
kshape <- read_sf("vectorfilesdata/kshape.shp")
# short duration token
gd_authenticate(auth_mode = "gcloud")
kshape <- read_sf("vectorfilesdata/kshape.shp")
kgrid <- rast(kshape, res = 10000)
kgrid <- as.polygons(kgrid)
kgrid$id <- 1:nrow(kgrid)
kgrid
kshape
kshape <- vect("vectorfilesdata/kshape.shp")
kgrid <- rast(kshape, res = 10000)
kgrid <- as.polygons(kgrid)
kgrid$id <- 1:nrow(kgrid)
intersection <- intersect(kshape, kgrid)
intersection
kgrid <- kgrid |>
filter(id %in% intersection$id)
ggplot() + geom_spatvector(data = kgrid)
ggplot(kgrid) +
geom_spatvector() +
theme_bw()
plot(kgrid)
#| echo: false
#| eval: true
#| include: true
#| fig-align: center
#| crop: true
kgrid <- rast(kshape, res = 5000)
?gd_install
library(terra)
temp <- rast("/Users/Josh/Downloads/landclass.tif")
temp
names(temp)
plot(temp[["urban-coverfraction"]])
library(terra)
temp <- rast("/Users/Josh/Downloads/nighttimelights.tif")
temp
plot(temp)
plot(log(temp))
# small area estimation code
library(tidyverse)
library(povmap)
library(survey)
library(haven)
# getting variance with the "direct" function
df <- read_dta("rastersdata/ihs5_consumption_aggregate.dta")
setwd("~/Dropbox/Papers/UN-SAE/workshops/asia/bangkokworkshop")
# small area estimation code
library(tidyverse)
library(povmap)
library(survey)
library(haven)
# getting variance with the "direct" function
df <- read_dta("rastersdata/ihs5_consumption_aggregate.dta")
df
library(tidyverse)
library(sf)
library(tidyterra)
library(terra)
library(cowplot)
library(kableExtra)
library(haven)
kdisgreen <- "#006334"
accent <- "#340063"
accent2 <- "#633400"
kdisgray <- "#A7A9AC"
library(tidyverse)
surveycollapsed <- read_csv("saedata/ihs5ea.csv")
predictors <- read_csv("saedata/mosaikvars.csv")
#| echo: true
#| include: true
library(glmnet)
set.seed(398465) # this is a random process, so we want to set the seed!
# we need to set up the data (combining the predictors and the outcome)
data <- surveycollapsed |>
left_join(predictors, by = "EA_CODE")
# cv.glmnet will set up everything for us
lasso <- cv.glmnet(
y = asin(sqrt(data$poor)), # the outcome
x = data |> dplyr::select(starts_with("mosaik")) |> as.matrix(), # the predictors (as.matrix() is required)
weights = data$total_weights, # the weights (sample weights)
nfolds = 5) # number of folds (10 is the default)
lasso
#| echo: true
#| include: true
# first, turn the coefs into a data.frame
coefs <- coef(lasso, s = "lambda.min") |>
as.matrix() |>
as.data.frame()
coefs
#| echo: true
#| include: true
# Now, create variable that is the name of the rows
coefs$variable <- rownames(coefs)
head(coefs)
# non-zero rows
coefs <- coefs[coefs$s1!=0,]
# finally, the names of the variables
coefs$variable
#| echo: true
#| include: true
#| # remove first value (the intercept)
allvariables <- coefs$variable[-1]
allvariables
#| echo: true
#| include: true
ebpformula <- as.formula(paste("poor ~", paste(allvariables, collapse = " + ")))
ebpformula
#| echo: true
#| include: true
library(povmap) # I like to use povmap instead of emdi (personal preference)
# get "area" variable
predictors$TA_CODE <- substr(predictors$EA_CODE, 1, 5)
data$TA_CODE <- substr(data$EA_CODE, 1, 5)
ebp <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
summary(ebp)
ebp$ind
ebp$MSE
means <- mean(data$poor)
means
names(means) <- "Mean"
ebpb <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
benchmark = means,
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
summary(ebpb)
ebp <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
seed = 123,
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
summary(ebp)
ebp$ind
ebp$MSE
ebpb <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
seed = 123,
benchmark = means,
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
ebpb$ind
ebp$ind
mean(ebpb$ind$Mean)
mean(ebp$ind$Mean)
ebpb <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
seed = 123,
benchmark = means,
benchmark_type = "raking",
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
mean(ebpb$ind$Mean)
mean(ebp$ind$Mean)
ebpb$MSE
ebp$MSE
mean(ebpb$MSE$Mean)
mean(ebp$MSE$Mean)
mean(ebpb$ind$Mean_bench)
mean(ebp$ind$Mean)
means
ebpb <- ebp(fixed = ebpformula, # the formula
pop_data = predictors, # the population data
pop_domains = "TA_CODE", # the domain (area) name in the population data
smp_data = data, # the sample data
smp_domains = "TA_CODE", # the domain (area) name in the sample data
transformation = "arcsin", # I'm going to use the arcsin transformation
weights = "total_weights", # sample weights
weights_type = "nlme", # weights type
seed = 123,
benchmark = means,
MSE = TRUE, # variance? yes please
L = 0) # this is a new thing in povmap: "analytical" point estimates. much faster!
summary(ebpb)
mean(ebpb$ind$Mean_bench)
mean(ebp$ind$Mean)
mean(ebpb$ind$Mean_bench)
mean(ebp$ind$Mean)
mean(ebpb$MSE$Mean)
mean(ebp$MSE$Mean)
ebpb$MSE
mean(ebpb$MSE$Mean_bench)
mean(ebp$MSE$Mean)
